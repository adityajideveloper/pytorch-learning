{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOku1e58CoyZ",
        "outputId": "0286b19b-0948-4113-850c-86473e7b9f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1_jdgBDnlU",
        "outputId": "25ee9976-cb43-4d86-f91c-29e2a94ee130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 15 12:01:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9tqf-SuEIV8"
      },
      "source": [
        "# Introduction to Tensors\n",
        "\n",
        "# Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64RoOVrEVVj",
        "outputId": "2d2935f0-23fb-4a72-e766-2eb28e8c4446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Scalar\n",
        "# https://pytorch.org/docs/stable/tensors.html\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id_Ovq7yEfeb",
        "outputId": "55cfdf3d-e17c-43ed-d877-5f78922f5177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4l88oxQFIKU",
        "outputId": "129d5de5-a3a0-4532-f53b-fe4e69d6f969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY1dhftVFMO7",
        "outputId": "b4dd1f29-5b8c-4a80-d3f9-8554f008db87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgnG0BxAFhJD",
        "outputId": "9e2f3eb0-9e11-47d3-b5c3-55c988c656d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxExOwR-FkWy",
        "outputId": "d76a8081-0123-44d6-9e13-f5405ce59a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIzHCeEXFooL",
        "outputId": "d1024f5f-1051-487d-ea52-63de238db1d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Matrix\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ6znSSHF2rP",
        "outputId": "0c8aa691-7424-44d6-cd29-02bdeae4a7bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNDdYmWfF7GT",
        "outputId": "168b360c-8f1b-4c38-fd17-626a4c0e7cba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "MATRIX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Z9AXWZGBpO",
        "outputId": "44a128af-8608-45d0-da8c-49fd849fee29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RE1ooaJGIRz",
        "outputId": "aada9a68-7044-452d-93ba-7beefbc59ca0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [7, 8, 9]]])\n",
        "\n",
        "TENSOR_TWO = torch.tensor([[[1, 2, 3],\n",
        "                            [4, 5, 6],\n",
        "                            [7, 8, 9]],\n",
        "                           [[11, 12, 13],\n",
        "                            [21, 22, 23],\n",
        "                            [31, 32, 33]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDpMEpzmGfhf",
        "outputId": "4584253a-c2ad-4bf4-a139-8b01969c3b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrhTlNSeGisf",
        "outputId": "1e3aceb2-53df-4e77-84e9-e52189ff163c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5QRp6igGmdX",
        "outputId": "c4475de8-e758-4fcf-e44a-4cfaf2a7c42a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6jhaNbUG1Nu",
        "outputId": "594c2c55-3d28-4e76-f27c-4de4b3a32788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "TENSOR[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upzLR13tHNZ7",
        "outputId": "a89900a6-84bf-4663-f8ac-16e57c33cd72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "TENSOR_TWO.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WyktupbHhX3"
      },
      "source": [
        "# Random Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbfEC4iaKYPJ",
        "outputId": "72b90362-9a7f-4f99-f9a2-09ae406de8bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2491, 0.5655, 0.2226, 0.1534],\n",
              "        [0.3613, 0.0837, 0.9098, 0.6865],\n",
              "        [0.4514, 0.5386, 0.8111, 0.1929]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# torch.rand\n",
        "# https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "\n",
        "random_tensor = torch.rand(3, 4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHwxwsM-LNsG",
        "outputId": "93f9a767-5ad2-47eb-a441-a7116e4aba93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.3777, 0.9625, 0.2135, 0.5642, 0.7943, 0.1545],\n",
              "          [0.2300, 0.4665, 0.6508, 0.8204, 0.4904, 0.3191],\n",
              "          [0.7748, 0.0994, 0.8681, 0.6873, 0.9908, 0.4467],\n",
              "          [0.4012, 0.1043, 0.7776, 0.6441, 0.1653, 0.6401],\n",
              "          [0.4454, 0.8829, 0.8493, 0.1298, 0.3886, 0.2204]],\n",
              "\n",
              "         [[0.9227, 0.6917, 0.6988, 0.1652, 0.0738, 0.6569],\n",
              "          [0.8503, 0.7897, 0.7793, 0.8435, 0.2234, 0.6749],\n",
              "          [0.5931, 0.6195, 0.2500, 0.9069, 0.5556, 0.3487],\n",
              "          [0.9144, 0.7909, 0.7641, 0.5496, 0.2017, 0.2166],\n",
              "          [0.6987, 0.0767, 0.2291, 0.8240, 0.1699, 0.7201]],\n",
              "\n",
              "         [[0.1069, 0.7938, 0.2143, 0.9798, 0.3845, 0.9061],\n",
              "          [0.3749, 0.7629, 0.8916, 0.7351, 0.5449, 0.3710],\n",
              "          [0.2718, 0.5792, 0.9330, 0.1779, 0.5071, 0.0715],\n",
              "          [0.3828, 0.3849, 0.6766, 0.2474, 0.3891, 0.8501],\n",
              "          [0.7865, 0.6843, 0.1528, 0.0981, 0.7714, 0.2714]],\n",
              "\n",
              "         [[0.5311, 0.5730, 0.0254, 0.8293, 0.4249, 0.8245],\n",
              "          [0.3321, 0.4495, 0.8159, 0.3463, 0.1659, 0.6077],\n",
              "          [0.8093, 0.7578, 0.2111, 0.7718, 0.0531, 0.7754],\n",
              "          [0.8614, 0.1902, 0.1279, 0.5019, 0.7336, 0.0976],\n",
              "          [0.3880, 0.3047, 0.6749, 0.0367, 0.6089, 0.9711]]],\n",
              "\n",
              "\n",
              "        [[[0.1647, 0.5913, 0.4474, 0.8801, 0.2642, 0.8610],\n",
              "          [0.6850, 0.3525, 0.8215, 0.7493, 0.3633, 0.5271],\n",
              "          [0.0019, 0.3516, 0.8283, 0.1495, 0.4144, 0.0028],\n",
              "          [0.4997, 0.1054, 0.4213, 0.3260, 0.1604, 0.4951],\n",
              "          [0.9973, 0.9912, 0.4607, 0.3243, 0.0881, 0.3869]],\n",
              "\n",
              "         [[0.2312, 0.9932, 0.1345, 0.5446, 0.4415, 0.6370],\n",
              "          [0.4829, 0.9692, 0.0937, 0.0542, 0.8478, 0.8630],\n",
              "          [0.4567, 0.7125, 0.9935, 0.9864, 0.4963, 0.5081],\n",
              "          [0.5489, 0.5450, 0.1948, 0.7448, 0.3745, 0.6396],\n",
              "          [0.1005, 0.5618, 0.8897, 0.3835, 0.3140, 0.8908]],\n",
              "\n",
              "         [[0.1263, 0.0086, 0.2652, 0.2787, 0.9270, 0.7851],\n",
              "          [0.8771, 0.8761, 0.0819, 0.7573, 0.4099, 0.4242],\n",
              "          [0.8951, 0.1165, 0.9490, 0.5443, 0.4253, 0.2323],\n",
              "          [0.1903, 0.8524, 0.4476, 0.3769, 0.4076, 0.5012],\n",
              "          [0.6394, 0.4526, 0.9556, 0.8559, 0.6252, 0.3910]],\n",
              "\n",
              "         [[0.7965, 0.4581, 0.0691, 0.2711, 0.5053, 0.1775],\n",
              "          [0.9831, 0.3279, 0.5479, 0.6745, 0.9011, 0.5785],\n",
              "          [0.7385, 0.1304, 0.2760, 0.5410, 0.1955, 0.8517],\n",
              "          [0.4073, 0.7454, 0.7809, 0.6288, 0.7406, 0.6983],\n",
              "          [0.2228, 0.8456, 0.3507, 0.1709, 0.2875, 0.1301]]],\n",
              "\n",
              "\n",
              "        [[[0.2605, 0.7357, 0.6560, 0.0794, 0.7001, 0.9747],\n",
              "          [0.5463, 0.0657, 0.0263, 0.5340, 0.8161, 0.3591],\n",
              "          [0.3345, 0.8163, 0.9679, 0.3426, 0.8081, 0.9634],\n",
              "          [0.3185, 0.0670, 0.8024, 0.4630, 0.1911, 0.7346],\n",
              "          [0.0283, 0.7670, 0.5831, 0.6891, 0.9358, 0.4199]],\n",
              "\n",
              "         [[0.9333, 0.8914, 0.4031, 0.6465, 0.1413, 0.5538],\n",
              "          [0.7970, 0.5322, 0.6272, 0.2211, 0.1605, 0.3599],\n",
              "          [0.0056, 0.9701, 0.1407, 0.3900, 0.7121, 0.9324],\n",
              "          [0.0179, 0.4472, 0.7145, 0.4603, 0.9504, 0.1499],\n",
              "          [0.2439, 0.9131, 0.9627, 0.3805, 0.5649, 0.8366]],\n",
              "\n",
              "         [[0.8688, 0.6357, 0.2719, 0.5211, 0.9545, 0.1852],\n",
              "          [0.8147, 0.1371, 0.9861, 0.0284, 0.0295, 0.6508],\n",
              "          [0.4810, 0.4984, 0.6869, 0.4134, 0.6180, 0.5873],\n",
              "          [0.3846, 0.6603, 0.6638, 0.4068, 0.2017, 0.6361],\n",
              "          [0.4263, 0.0767, 0.4342, 0.3414, 0.7789, 0.5724]],\n",
              "\n",
              "         [[0.6719, 0.2074, 0.2623, 0.1959, 0.0136, 0.7048],\n",
              "          [0.8725, 0.0453, 0.9674, 0.4629, 0.0041, 0.9643],\n",
              "          [0.1012, 0.3477, 0.3503, 0.4392, 0.2615, 0.5926],\n",
              "          [0.3233, 0.4861, 0.4538, 0.3023, 0.2798, 0.9348],\n",
              "          [0.2962, 0.8026, 0.6992, 0.6556, 0.4171, 0.4115]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "random_tensor.ndim\n",
        "\n",
        "random_multiple_dimesion = torch.rand(3, 4, 5, 6)\n",
        "random_multiple_dimesion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv07A9zILjMZ",
        "outputId": "5846dfa2-55cd-4dd4-e0e2-861df9610375"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "random_multiple_dimesion.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDAb6U8ILtcS",
        "outputId": "99eaae6b-a913-4e18-8f02-6569300e28d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "random_multiple_dimesion.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd5fZ_uNMV-X"
      },
      "source": [
        "![image.png](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaFuWQ-qLv_C",
        "outputId": "50433117-0168-4200-ff65-6474fa2db62e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.5272, 0.8493, 0.7067],\n",
              "          [0.8123, 0.2822, 0.0387],\n",
              "          [0.0363, 0.9368, 0.4221],\n",
              "          ...,\n",
              "          [0.2263, 0.6668, 0.0793],\n",
              "          [0.8939, 0.5499, 0.2588],\n",
              "          [0.6520, 0.9746, 0.1490]],\n",
              " \n",
              "         [[0.1188, 0.6255, 0.5008],\n",
              "          [0.2647, 0.0205, 0.4516],\n",
              "          [0.2402, 0.1507, 0.1990],\n",
              "          ...,\n",
              "          [0.6643, 0.8768, 0.1065],\n",
              "          [0.0873, 0.1720, 0.1651],\n",
              "          [0.0717, 0.3718, 0.5767]],\n",
              " \n",
              "         [[0.7934, 0.5250, 0.9419],\n",
              "          [0.0235, 0.6842, 0.7345],\n",
              "          [0.5330, 0.5130, 0.0390],\n",
              "          ...,\n",
              "          [0.9524, 0.4974, 0.1387],\n",
              "          [0.5358, 0.6802, 0.9658],\n",
              "          [0.2752, 0.2122, 0.5188]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.7991, 0.7326, 0.8770],\n",
              "          [0.9426, 0.9462, 0.7970],\n",
              "          [0.4146, 0.2866, 0.5397],\n",
              "          ...,\n",
              "          [0.4924, 0.2699, 0.0013],\n",
              "          [0.1578, 0.0608, 0.4103],\n",
              "          [0.5037, 0.7814, 0.0752]],\n",
              " \n",
              "         [[0.9648, 0.3858, 0.6673],\n",
              "          [0.6040, 0.2554, 0.2805],\n",
              "          [0.0308, 0.6460, 0.6591],\n",
              "          ...,\n",
              "          [0.7459, 0.3334, 0.0069],\n",
              "          [0.1241, 0.8255, 0.3325],\n",
              "          [0.5801, 0.8563, 0.5115]],\n",
              " \n",
              "         [[0.8953, 0.7087, 0.4042],\n",
              "          [0.7182, 0.5935, 0.4107],\n",
              "          [0.7924, 0.3806, 0.1100],\n",
              "          ...,\n",
              "          [0.8727, 0.5744, 0.9862],\n",
              "          [0.2526, 0.5935, 0.0235],\n",
              "          [0.6107, 0.5852, 0.6148]]]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # Height, width, color channel (R, G, B)\n",
        "random_image_size_tensor, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wz_tqpBMtno",
        "outputId": "3b380142-c7ef-4288-c623-d78905d9b1bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Creating a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv_OO6MMM_KD",
        "outputId": "c1ac6e19-0d07-4e20-f888-43d6f3791009"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWniv970PxJn"
      },
      "source": [
        "Tensor Datatypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rICIr-0WP0Si",
        "outputId": "ef83780c-422e-461a-89d5-7217dc9080c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None)\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyxxKx-EQPRl",
        "outputId": "c2fd33a8-36bb-405e-c0dc-fe9a861fbc0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, tensor([3., 6., 9.], dtype=torch.float16))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
        "\n",
        "float_32_tensor.dtype, float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hgHoPOxQoV6",
        "outputId": "5432343d-3b2b-4466-f119-a0464c6d99e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "float_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                            dtype=None, # Data Types eg.: flot32 (Default), float16, float64, etc. used in Precision in Computer\n",
        "                            device=None, # defaults to None, which uses the default tensor type eg.: \"cpu\", \"cuda\", etc\n",
        "                            requires_grad=False # if True, operations performed on the tensor are recorded\n",
        "                            )\n",
        "\n",
        "float_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m48cYuZJS4hS",
        "outputId": "24f72044-3755-4f6b-ba05-05a46bd98df4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "multiplied_tensor = float_16_tensor * float_32_tensor\n",
        "\n",
        "multiplied_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yc7UqP-ITbAz"
      },
      "outputs": [],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)\n",
        "\n",
        "multiplied_int_tensor = int_32_tensor * float_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_v6qIQ1TnfR",
        "outputId": "0666cbc9-5309-4be0-da31-953888b7be85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "float_32_tensor.device, float_32_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fcx_4tdhe6T"
      },
      "source": [
        "### Manipulating Tensors\n",
        "Tensor Operations includes:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQwlADQ1h6ER",
        "outputId": "cb811541-2cf9-4033-8c8d-1c7501d27a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "o_tensor = torch.tensor([1, 2, 3])\n",
        "o_tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv4mU9-_iPN8",
        "outputId": "5f51cd56-6f11-4f11-cca5-89fba28d0c0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "o_tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-AP9-HDiVvM",
        "outputId": "0812c2cd-c1bc-4f54-8939-5465eb05bf79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "o_tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goncKPwrieB6",
        "outputId": "8d86d94e-13bf-4c89-e765-cb2d6b5cc8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30])\n",
            "tensor([11, 12, 13])\n",
            "tensor([-9, -8, -7])\n"
          ]
        }
      ],
      "source": [
        "print(torch.mul(o_tensor, 10))\n",
        "print(torch.add(o_tensor, 10))\n",
        "print(torch.sub(o_tensor, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuwEciN_i_Xg"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMsycohgjLuE",
        "outputId": "36d8734c-ea92-48f0-a88c-89626a8d161d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Element-wise\n",
        "o_tensor * o_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBruVOugjl_A",
        "outputId": "22251406-b11c-463f-9ccd-1de1f3acf1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.22 ms, sys: 38 µs, total: 1.26 ms\n",
            "Wall time: 1.42 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Matrix Multiplication\n",
        "torch.matmul(o_tensor, o_tensor)\n",
        "\n",
        "# torch.mm is same as torch.matmul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGiTdOg-kh6m"
      },
      "source": [
        "## Common Errors in Deep Learning is Shape Error (Basic High School Maths)\n",
        "1. The **inner dimensions** must match:\n",
        "* `(3,2) @ (3,2)` won't work\n",
        "* `(2,3) @ (3,2)` will work\n",
        "* *similarly, `n` numst be equal to `p`*\n",
        "2. The resulting Matrix has shape `m x q` for two matrix of order `m x n` and `p x n`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d11xIMB5CBs",
        "outputId": "98530567-2452-4172-e668-b41a51cd836b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same Matrix => tensor([[0.9694, 0.9006],\n",
            "        [0.3250, 0.8531],\n",
            "        [0.4222, 0.4721]])\n",
            "Transpose Matrix => tensor([[0.9694, 0.3250, 0.4222],\n",
            "        [0.9006, 0.8531, 0.4721]])\n"
          ]
        }
      ],
      "source": [
        "# Transpose of a Matrix\n",
        "sample_tensor_transpose = torch.rand(3,2)\n",
        "print(f\"Same Matrix => {sample_tensor_transpose}\")\n",
        "print(f\"Transpose Matrix => {sample_tensor_transpose.T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAcmuFlQ8VQQ"
      },
      "source": [
        "## Finding the min, max, mean, sum, etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5MNwuaV8jTM",
        "outputId": "b7875ec5-6fc4-4042-8636-6e099c0f68c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sample_tensor = torch.arange(0, 100, 10) # From, To, Length\n",
        "sample_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adlbaQc-82qk",
        "outputId": "d2bff4b4-943b-498e-f1de-bdccdf26533b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Find the min\n",
        "torch.min(sample_tensor), sample_tensor.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoA-cNmC8939",
        "outputId": "67305a26-ecee-444d-b6ff-405987dfb709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Find the max\n",
        "torch.max(sample_tensor), sample_tensor.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CJR-1ft9FG7",
        "outputId": "863a64de-67f9-4eb1-9d82-408a5550ab50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Find the mean\n",
        "# Finding the mean requires the tensor to be of datatype of float32\n",
        "torch.mean(sample_tensor.type(torch.float32)), sample_tensor.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxpgqnd-9hGM",
        "outputId": "c0fecd5c-568f-4232-e15b-8979cc41ea81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Find Sum\n",
        "torch.sum(sample_tensor), sample_tensor.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqb5Hacq95yY"
      },
      "source": [
        "## Finding the position min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnVNA5fs-YfP",
        "outputId": "9d993abb-54ac-4044-bf5b-6a61e9551385"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "sample_tensor.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1bP2Z2J-hJx",
        "outputId": "a2ea4e52-c397-4389-cd8b-250a79163f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "sample_tensor.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKbu4fl1-sml"
      },
      "source": [
        "## Reshaping, Stacking, Squeezing, and unsqueezing tensors\n",
        "* Reshaping - *Reshape an tensor to a different shape*\n",
        "* View - *Return a view of an input tensor of certain shape but keep the same memory*\n",
        "* Stacking - *Combining multiple tensors on top of each other (vstack) or side by side (hstack)*\n",
        "* Squeeze - *Removes all `1` diminesions from a tensor*\n",
        "* Unsequeeze - *Add a `1` dimension to a target tensor*\n",
        "* Permute - *Return a view of the input with dimensions permuted (swapped) in a certain way*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak3HfiN5_SM3",
        "outputId": "bc688c43-5214-403b-86ee-f462a8808ca5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 10, 20, 30, 40],\n",
              "        [50, 60, 70, 80, 90]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Change the shape\n",
        "sample_tensor.reshape(2, 5) # <- order of new matrix must match the no. of elements with prev. matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJNfjG3cAjPp",
        "outputId": "ed9a3147-2a36-41ab-e434-3da8ac4a9c51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0],\n",
              "        [10],\n",
              "        [20],\n",
              "        [30],\n",
              "        [40],\n",
              "        [50],\n",
              "        [60],\n",
              "        [70],\n",
              "        [80],\n",
              "        [90]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Change the view\n",
        "sample_tensor.view(10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxm_SUgBZXs",
        "outputId": "ef70d9c3-31a3-4852-834a-260bc843bffb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
              "        [ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
              "        [ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
              "        [ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Stack tensor\n",
        "torch.stack([sample_tensor, sample_tensor, sample_tensor, sample_tensor], dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzKildo6B3Tr",
        "outputId": "374e8d51-053f-43be-e038-3b6ac825d066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Tensor => tensor([[[8.1604e-02, 5.5777e-01, 5.6519e-01, 3.7949e-01, 3.2019e-01,\n",
            "          1.2512e-02, 1.7232e-01, 6.1989e-01, 2.6611e-01, 8.8171e-01,\n",
            "          4.3468e-01, 4.8534e-01, 6.5356e-01, 8.2544e-01, 5.5690e-03,\n",
            "          7.9273e-01, 3.9011e-01, 9.1248e-01, 4.9983e-01, 1.5944e-01,\n",
            "          9.3060e-01, 3.9573e-01, 9.1588e-01, 5.9542e-01, 1.6326e-01,\n",
            "          6.8410e-01, 4.8002e-01, 8.4797e-01, 4.1669e-01, 8.5191e-01,\n",
            "          1.2811e-01, 5.9065e-02, 5.2418e-01, 4.9123e-01, 3.2916e-01,\n",
            "          7.8653e-01, 8.3126e-01, 1.2715e-01, 8.7355e-01, 7.7170e-01,\n",
            "          4.6341e-01, 9.4083e-01, 7.8896e-01, 7.4822e-01, 6.8038e-01,\n",
            "          7.7032e-01, 6.7850e-01, 3.8958e-01, 9.7527e-01, 3.4469e-01,\n",
            "          8.1498e-01, 8.6578e-01, 6.6221e-01, 8.6281e-01, 4.5094e-01,\n",
            "          7.3580e-01, 6.7423e-01, 3.5662e-01, 5.3104e-02, 9.5417e-01,\n",
            "          9.4645e-01, 1.1101e-01, 6.3186e-01, 2.1569e-01, 6.7742e-01,\n",
            "          6.4431e-01, 2.2300e-01, 9.5500e-01, 1.4852e-02, 8.3962e-01,\n",
            "          6.9381e-01, 3.3548e-01, 4.9906e-01, 3.4343e-01, 5.6934e-01,\n",
            "          8.1845e-01, 2.6498e-01, 6.8615e-01, 4.3283e-02, 1.7469e-01,\n",
            "          1.8154e-01, 1.4030e-01, 6.9019e-01, 9.9014e-01, 1.6014e-01,\n",
            "          2.7892e-01, 5.7342e-01, 8.6232e-01, 9.1273e-01, 3.6259e-01,\n",
            "          2.1953e-01, 8.8377e-01, 4.7724e-01, 2.9237e-01, 3.9218e-01,\n",
            "          7.8276e-01, 1.0560e-01, 8.2764e-01, 1.3670e-01, 7.3285e-01],\n",
            "         [4.9379e-01, 4.7179e-01, 5.4416e-02, 4.4436e-01, 3.2117e-01,\n",
            "          3.7833e-01, 6.2396e-01, 5.8305e-01, 8.8853e-01, 7.1775e-01,\n",
            "          8.8945e-01, 3.8520e-01, 8.8743e-01, 2.5975e-01, 1.0780e-01,\n",
            "          3.5379e-01, 7.2312e-01, 5.7147e-01, 4.7541e-01, 3.3298e-01,\n",
            "          2.6006e-01, 6.9873e-01, 3.7825e-01, 9.2003e-01, 1.1777e-01,\n",
            "          1.3912e-01, 7.4862e-01, 1.3541e-01, 2.5663e-01, 8.3319e-02,\n",
            "          3.4187e-03, 1.1694e-01, 1.4547e-01, 6.4514e-01, 9.1890e-01,\n",
            "          7.3544e-02, 4.7098e-01, 4.3243e-01, 8.0100e-01, 5.1714e-01,\n",
            "          8.3063e-01, 7.8397e-01, 5.9988e-01, 1.1653e-01, 8.3550e-01,\n",
            "          6.5963e-01, 9.9422e-01, 7.2435e-01, 8.6224e-01, 5.7468e-01,\n",
            "          6.5998e-01, 4.4009e-01, 3.2861e-01, 8.8829e-01, 8.0788e-01,\n",
            "          2.9573e-01, 6.9762e-01, 9.5532e-01, 1.3452e-01, 4.4884e-01,\n",
            "          9.7599e-01, 8.9558e-01, 1.8005e-01, 7.0973e-01, 7.8130e-01,\n",
            "          1.6482e-01, 9.3218e-01, 2.6945e-02, 5.5373e-01, 9.1742e-01,\n",
            "          3.4987e-01, 1.6252e-01, 9.9281e-01, 6.5369e-01, 5.9247e-01,\n",
            "          6.4272e-03, 6.2088e-01, 3.2128e-01, 9.7426e-01, 8.2028e-01,\n",
            "          8.9175e-01, 6.2385e-01, 4.3105e-01, 2.3491e-01, 4.2317e-02,\n",
            "          8.4752e-01, 1.5455e-01, 2.7437e-01, 8.2425e-01, 2.5594e-01,\n",
            "          2.0665e-01, 1.8698e-01, 9.8314e-01, 7.8676e-01, 1.4423e-01,\n",
            "          1.6599e-01, 6.6638e-01, 4.6804e-01, 4.2403e-01, 1.5219e-02],\n",
            "         [8.9710e-01, 3.8614e-01, 9.1983e-01, 3.2239e-01, 7.5455e-01,\n",
            "          2.0981e-01, 1.1402e-01, 9.0821e-01, 4.9300e-01, 9.6049e-01,\n",
            "          2.4092e-01, 5.3498e-01, 8.3712e-01, 7.9205e-01, 4.0875e-01,\n",
            "          1.6997e-01, 2.7440e-01, 4.6876e-01, 4.8785e-01, 3.9914e-01,\n",
            "          2.9420e-01, 1.5941e-01, 6.3762e-01, 1.9890e-01, 3.7626e-01,\n",
            "          2.0711e-02, 6.4073e-01, 3.8797e-01, 4.4856e-01, 3.0641e-01,\n",
            "          5.1959e-01, 2.9773e-01, 5.6938e-01, 7.2921e-01, 5.9699e-01,\n",
            "          8.5356e-01, 1.6477e-01, 6.9372e-01, 7.2739e-01, 7.8713e-01,\n",
            "          2.8702e-01, 2.5858e-01, 7.5933e-01, 8.2470e-01, 4.8321e-02,\n",
            "          5.8675e-01, 4.8427e-01, 5.4681e-01, 6.0229e-01, 4.8146e-01,\n",
            "          9.8026e-01, 2.1456e-01, 3.1532e-02, 1.1794e-01, 3.8199e-01,\n",
            "          1.5283e-01, 8.8701e-01, 5.7179e-01, 9.4359e-01, 3.8320e-01,\n",
            "          9.6146e-01, 8.2092e-01, 8.8474e-01, 7.2843e-01, 5.3729e-01,\n",
            "          1.7147e-01, 8.1177e-01, 3.4561e-02, 8.7886e-01, 2.3712e-02,\n",
            "          1.4595e-02, 2.4431e-01, 9.5750e-01, 7.5839e-01, 7.3774e-01,\n",
            "          7.1405e-01, 9.2229e-01, 7.5880e-01, 8.7377e-01, 7.5622e-01,\n",
            "          3.9538e-01, 2.4556e-01, 8.4242e-01, 5.3809e-01, 5.6869e-01,\n",
            "          9.2777e-01, 2.3969e-01, 5.5497e-01, 6.0058e-01, 7.3298e-01,\n",
            "          7.3540e-01, 1.2897e-01, 3.8541e-01, 6.0954e-01, 4.7350e-01,\n",
            "          7.9805e-01, 3.1176e-01, 7.6926e-01, 3.0273e-01, 8.3686e-01],\n",
            "         [8.5666e-01, 4.1014e-01, 7.5651e-02, 2.2745e-01, 6.0618e-01,\n",
            "          3.6895e-01, 8.8093e-01, 7.9922e-01, 5.7872e-01, 5.1862e-01,\n",
            "          3.9345e-01, 5.8056e-01, 4.7532e-01, 4.0924e-01, 1.2129e-01,\n",
            "          2.8682e-01, 5.8737e-01, 2.9768e-01, 9.0810e-01, 4.9628e-01,\n",
            "          1.3460e-01, 7.5155e-04, 2.2354e-01, 6.6266e-01, 5.1926e-02,\n",
            "          7.5302e-01, 4.6018e-01, 2.3694e-01, 1.7598e-01, 9.5301e-01,\n",
            "          2.4007e-01, 7.6604e-01, 6.4258e-01, 8.4256e-02, 4.3477e-01,\n",
            "          7.1603e-02, 3.8188e-01, 8.9135e-01, 2.0361e-01, 6.6801e-01,\n",
            "          8.4255e-01, 8.2312e-01, 2.7793e-01, 1.4844e-02, 1.9442e-01,\n",
            "          5.2749e-01, 1.8118e-01, 4.3881e-01, 6.5011e-01, 7.2415e-01,\n",
            "          7.9951e-01, 7.2039e-01, 3.3775e-01, 2.6525e-01, 9.9489e-01,\n",
            "          5.0473e-02, 2.6831e-02, 9.5467e-01, 5.0583e-03, 5.2839e-01,\n",
            "          6.5688e-01, 4.0454e-02, 4.9444e-01, 1.2266e-01, 8.5652e-01,\n",
            "          7.6906e-01, 9.6811e-01, 4.3548e-01, 8.9473e-01, 5.5119e-01,\n",
            "          8.1008e-01, 5.3387e-01, 7.4509e-01, 4.3774e-01, 4.2295e-02,\n",
            "          6.3805e-01, 9.3541e-01, 6.1343e-01, 7.4858e-01, 6.1320e-01,\n",
            "          6.5144e-01, 8.8216e-01, 6.6199e-01, 8.2705e-01, 6.3482e-02,\n",
            "          4.3303e-01, 8.2646e-01, 2.9834e-01, 3.5401e-01, 5.2112e-01,\n",
            "          8.0164e-01, 4.5772e-01, 1.9599e-01, 8.0110e-01, 9.7125e-01,\n",
            "          4.0026e-01, 9.9644e-01, 1.5238e-02, 2.1858e-01, 3.3094e-01],\n",
            "         [5.5760e-01, 2.4287e-02, 2.3710e-01, 8.1990e-01, 5.3880e-01,\n",
            "          5.6573e-02, 3.5348e-01, 9.8622e-01, 3.6928e-01, 8.8121e-01,\n",
            "          9.0502e-01, 4.4158e-01, 6.7281e-01, 8.3276e-01, 6.6396e-01,\n",
            "          3.9647e-01, 6.5557e-01, 8.3160e-02, 8.3060e-01, 5.8533e-01,\n",
            "          1.9888e-01, 6.0536e-01, 7.4321e-01, 7.8743e-01, 5.1744e-01,\n",
            "          9.3815e-01, 5.9315e-01, 7.3235e-01, 9.8011e-01, 2.9319e-01,\n",
            "          7.7446e-01, 4.0531e-01, 7.4763e-01, 1.8435e-01, 1.6122e-01,\n",
            "          5.1568e-02, 1.7039e-01, 4.7281e-01, 6.9080e-01, 5.2760e-01,\n",
            "          8.8943e-01, 6.3504e-01, 8.1975e-01, 1.8367e-01, 3.4998e-01,\n",
            "          7.4728e-01, 9.5700e-01, 2.7789e-01, 1.7008e-01, 2.7849e-01,\n",
            "          6.3448e-01, 8.2628e-01, 7.5297e-01, 6.8430e-01, 5.4233e-01,\n",
            "          8.9443e-02, 8.2021e-02, 6.6746e-02, 4.6808e-01, 6.8834e-01,\n",
            "          9.7994e-01, 5.5460e-01, 6.2737e-01, 5.1655e-01, 5.5226e-01,\n",
            "          8.1527e-01, 3.7730e-01, 3.8661e-01, 7.5906e-01, 7.3761e-01,\n",
            "          1.9154e-01, 2.4236e-01, 3.1135e-01, 8.2483e-01, 2.3637e-01,\n",
            "          6.1773e-01, 7.3636e-01, 1.1177e-01, 7.0790e-02, 8.9771e-01,\n",
            "          3.6944e-01, 2.8843e-01, 2.1256e-01, 1.2428e-01, 2.6285e-01,\n",
            "          8.5046e-01, 1.4815e-01, 3.5555e-02, 6.6550e-01, 1.4833e-02,\n",
            "          4.6746e-01, 6.4069e-01, 8.6999e-02, 6.5289e-02, 5.8209e-01,\n",
            "          5.6635e-01, 4.5597e-01, 3.4372e-01, 8.0028e-01, 9.9415e-01],\n",
            "         [4.9216e-01, 2.2926e-01, 9.0298e-01, 5.2460e-01, 5.8827e-01,\n",
            "          2.1132e-01, 6.1273e-01, 5.9781e-01, 9.4003e-01, 2.3373e-01,\n",
            "          9.1015e-01, 8.6877e-01, 7.6851e-01, 7.7474e-02, 2.4443e-01,\n",
            "          1.3557e-01, 9.6276e-01, 3.9708e-01, 1.7116e-01, 2.5752e-01,\n",
            "          6.1215e-01, 4.3173e-01, 6.0824e-01, 9.3718e-01, 5.8026e-01,\n",
            "          7.0295e-01, 8.2294e-02, 3.2328e-01, 3.8144e-01, 7.0627e-01,\n",
            "          4.7214e-01, 9.1737e-01, 1.1425e-01, 6.8436e-01, 1.5304e-01,\n",
            "          7.7538e-01, 1.4189e-01, 3.9480e-01, 6.6934e-01, 3.8167e-01,\n",
            "          5.7738e-01, 8.8676e-01, 5.0065e-01, 4.3308e-01, 6.5484e-02,\n",
            "          2.7814e-01, 3.6086e-01, 5.1347e-01, 9.3324e-01, 5.9976e-01,\n",
            "          7.4165e-02, 8.0759e-01, 3.9357e-01, 6.6381e-01, 4.0661e-01,\n",
            "          7.3815e-02, 5.9148e-02, 7.9355e-01, 1.7464e-01, 7.3468e-01,\n",
            "          2.4547e-01, 1.6831e-01, 8.1506e-01, 1.1917e-01, 7.5982e-01,\n",
            "          2.2406e-01, 8.3595e-02, 3.6903e-01, 2.2881e-02, 6.9469e-01,\n",
            "          5.6277e-02, 2.4852e-01, 2.6646e-01, 8.9334e-01, 8.5232e-01,\n",
            "          1.0116e-01, 9.7033e-01, 8.1707e-01, 2.7544e-01, 9.9243e-01,\n",
            "          1.3152e-01, 5.3615e-01, 1.8501e-01, 3.4566e-01, 6.7314e-02,\n",
            "          5.3763e-01, 8.7770e-01, 1.2453e-02, 3.3808e-01, 3.1706e-01,\n",
            "          1.0941e-01, 7.8152e-01, 4.5194e-01, 8.5031e-01, 8.2695e-01,\n",
            "          9.3166e-01, 2.2278e-01, 8.9762e-01, 5.4592e-01, 9.7383e-02],\n",
            "         [4.9688e-01, 6.0564e-01, 1.0975e-01, 4.6906e-01, 7.5482e-01,\n",
            "          1.3295e-01, 1.4914e-02, 9.2749e-01, 8.4527e-01, 7.3350e-01,\n",
            "          6.3306e-01, 9.4032e-01, 2.8511e-01, 7.5571e-01, 3.7585e-01,\n",
            "          2.0939e-01, 6.3213e-01, 4.2246e-01, 1.2931e-01, 5.3284e-01,\n",
            "          7.6758e-01, 6.7461e-01, 6.2525e-01, 4.7481e-01, 7.9622e-01,\n",
            "          4.8895e-01, 8.6369e-01, 2.5319e-01, 7.2130e-02, 8.5200e-01,\n",
            "          9.6786e-01, 3.9654e-01, 4.2059e-01, 9.2551e-01, 4.9140e-01,\n",
            "          5.9309e-01, 3.9196e-01, 8.5716e-01, 7.7089e-02, 4.7541e-01,\n",
            "          3.1886e-02, 8.1179e-01, 3.8046e-01, 9.3863e-01, 3.1259e-02,\n",
            "          9.5448e-01, 8.3809e-01, 8.4015e-01, 5.5805e-01, 1.8507e-02,\n",
            "          5.3514e-01, 7.4110e-01, 1.9651e-01, 3.7031e-03, 8.9149e-01,\n",
            "          4.1730e-02, 1.9716e-01, 5.2132e-01, 3.5379e-01, 7.5895e-01,\n",
            "          2.6121e-01, 2.3325e-01, 7.7538e-01, 8.2272e-01, 5.3274e-01,\n",
            "          3.4224e-01, 7.5411e-01, 6.0686e-01, 8.2289e-01, 2.1956e-01,\n",
            "          9.6206e-01, 2.1804e-01, 5.9248e-01, 1.9277e-01, 4.3712e-01,\n",
            "          2.7056e-02, 7.4482e-02, 9.2578e-01, 3.5622e-02, 9.3093e-01,\n",
            "          7.4074e-01, 6.0816e-02, 3.1421e-01, 3.5951e-01, 1.8807e-02,\n",
            "          3.1099e-01, 6.1311e-01, 5.5567e-02, 2.5482e-01, 5.0629e-01,\n",
            "          6.0218e-01, 2.1629e-01, 6.6213e-01, 9.6920e-01, 3.0341e-02,\n",
            "          5.9581e-01, 4.6293e-02, 1.8732e-01, 1.0272e-01, 5.0797e-01],\n",
            "         [9.1922e-02, 2.2984e-01, 9.2291e-01, 1.6880e-01, 3.4835e-01,\n",
            "          8.3818e-01, 4.8758e-01, 5.7774e-01, 9.0886e-01, 8.6973e-01,\n",
            "          4.6522e-02, 8.2608e-01, 7.5623e-01, 7.1496e-01, 5.3306e-01,\n",
            "          2.1942e-01, 8.9613e-01, 2.9938e-01, 4.6249e-01, 9.8408e-01,\n",
            "          3.8674e-01, 5.1225e-01, 9.7515e-01, 3.0752e-01, 8.0774e-01,\n",
            "          9.9406e-01, 1.9198e-02, 6.3799e-01, 1.3960e-01, 8.0611e-01,\n",
            "          7.1206e-01, 9.1977e-01, 3.1428e-01, 4.0985e-01, 7.9711e-02,\n",
            "          7.3937e-01, 6.7437e-01, 5.0170e-01, 5.2236e-01, 4.6456e-01,\n",
            "          1.3023e-01, 1.6083e-01, 3.8296e-01, 9.8477e-01, 9.6826e-01,\n",
            "          1.6527e-01, 8.7771e-02, 4.9545e-01, 2.4207e-01, 3.7992e-01,\n",
            "          7.1440e-01, 6.7005e-01, 4.9089e-01, 6.1760e-01, 8.2575e-01,\n",
            "          1.9467e-01, 7.6233e-01, 3.6020e-01, 7.0424e-01, 9.5864e-01,\n",
            "          6.8257e-01, 1.4502e-01, 4.0414e-01, 5.1002e-01, 8.3246e-01,\n",
            "          8.4279e-02, 7.3733e-01, 8.4785e-01, 5.4074e-01, 5.7334e-01,\n",
            "          6.9740e-01, 5.8486e-01, 4.2189e-01, 6.0167e-02, 6.1128e-01,\n",
            "          1.1322e-03, 2.1129e-01, 4.2087e-01, 7.7676e-01, 4.7528e-01,\n",
            "          3.4107e-01, 5.6177e-01, 7.0480e-02, 3.8296e-01, 7.1026e-01,\n",
            "          5.2474e-01, 3.2610e-01, 2.4301e-01, 5.6124e-01, 1.4933e-01,\n",
            "          2.4445e-01, 3.9273e-01, 4.7381e-02, 4.9978e-01, 3.7503e-01,\n",
            "          2.6423e-01, 7.4381e-01, 2.1931e-01, 3.1156e-01, 2.6164e-01],\n",
            "         [7.8031e-01, 9.2238e-01, 5.9437e-01, 2.2310e-01, 9.1493e-01,\n",
            "          4.7888e-02, 1.9700e-01, 4.5609e-01, 4.7607e-01, 8.0723e-01,\n",
            "          3.6083e-01, 9.9307e-02, 1.4651e-01, 5.2565e-01, 2.8749e-01,\n",
            "          3.8038e-01, 8.3197e-01, 4.6182e-01, 7.7102e-01, 8.1967e-01,\n",
            "          9.2963e-02, 5.6504e-01, 6.7127e-01, 6.2465e-01, 9.1402e-02,\n",
            "          8.6855e-01, 8.3324e-01, 9.6535e-01, 9.9604e-01, 9.8357e-02,\n",
            "          4.3758e-01, 6.9799e-01, 6.2288e-01, 2.0490e-01, 6.3233e-01,\n",
            "          5.1610e-01, 2.4545e-01, 3.2241e-01, 4.2124e-01, 2.4819e-01,\n",
            "          9.6619e-01, 9.9727e-01, 2.2853e-01, 8.0506e-02, 8.2617e-01,\n",
            "          8.8029e-01, 9.0084e-01, 8.8318e-01, 4.9683e-01, 1.2244e-01,\n",
            "          7.8584e-01, 6.3234e-01, 2.6526e-01, 6.1956e-01, 8.9735e-01,\n",
            "          5.9981e-01, 9.1454e-01, 3.9219e-01, 8.1973e-02, 3.8248e-01,\n",
            "          2.2588e-03, 8.3259e-02, 9.1844e-01, 9.9542e-01, 8.8968e-02,\n",
            "          9.2397e-02, 9.2259e-01, 9.6676e-01, 3.1658e-01, 4.6494e-01,\n",
            "          9.5755e-01, 5.5791e-01, 5.5294e-01, 2.5004e-01, 2.7448e-01,\n",
            "          7.7983e-01, 6.6146e-01, 2.0756e-01, 7.3926e-01, 4.6697e-01,\n",
            "          4.7706e-02, 2.8990e-01, 8.0746e-01, 3.6450e-01, 9.4200e-01,\n",
            "          4.8792e-01, 4.3089e-01, 8.9807e-01, 5.8669e-01, 8.2714e-01,\n",
            "          2.5559e-02, 5.9312e-01, 2.3710e-01, 9.0918e-01, 5.3074e-01,\n",
            "          8.8331e-01, 2.6732e-01, 4.6857e-01, 2.4054e-01, 4.1548e-02],\n",
            "         [5.0777e-01, 7.3561e-01, 3.0758e-01, 9.0041e-01, 8.7596e-01,\n",
            "          2.8808e-01, 5.6304e-01, 6.6406e-01, 7.1591e-01, 6.6498e-01,\n",
            "          5.7052e-02, 3.5576e-01, 1.2584e-01, 7.0323e-01, 9.3095e-01,\n",
            "          9.2346e-01, 8.3435e-01, 6.6363e-01, 4.9003e-01, 9.3112e-01,\n",
            "          2.9740e-01, 7.4738e-01, 8.8002e-01, 6.7925e-01, 1.0912e-01,\n",
            "          2.2722e-01, 1.6617e-01, 4.9386e-01, 8.9069e-01, 8.0928e-01,\n",
            "          5.5567e-02, 5.2950e-01, 8.4768e-01, 3.2670e-01, 2.6487e-01,\n",
            "          6.9438e-01, 2.4298e-01, 2.0627e-01, 4.2871e-01, 9.1508e-01,\n",
            "          8.4105e-01, 4.8293e-01, 1.5354e-01, 9.0041e-01, 9.4235e-01,\n",
            "          2.0541e-01, 6.4841e-01, 4.4715e-01, 8.5982e-01, 9.8417e-01,\n",
            "          7.8113e-01, 6.4699e-01, 8.1906e-01, 1.2873e-01, 8.2257e-01,\n",
            "          8.9249e-01, 9.7299e-01, 7.3562e-01, 8.9181e-01, 7.6237e-02,\n",
            "          1.3581e-01, 5.2349e-01, 1.3105e-01, 9.4061e-01, 5.3122e-02,\n",
            "          2.2651e-01, 8.8751e-02, 6.8909e-01, 3.4628e-01, 9.5912e-01,\n",
            "          6.7650e-01, 7.2814e-01, 7.2114e-01, 3.6751e-01, 1.0379e-01,\n",
            "          5.3341e-01, 3.5823e-01, 6.2625e-01, 2.0114e-01, 2.0115e-01,\n",
            "          4.4724e-01, 4.6196e-01, 8.3058e-02, 6.1603e-01, 7.7117e-01,\n",
            "          7.5126e-01, 6.8695e-01, 4.4773e-01, 5.4067e-01, 2.0093e-01,\n",
            "          1.1027e-01, 5.9807e-01, 6.0012e-01, 8.3143e-01, 5.5640e-01,\n",
            "          8.2894e-01, 7.0163e-01, 3.9171e-01, 1.4883e-01, 7.4562e-01]]])\n",
            "Shape of sample Tensor => torch.Size([1, 10, 100])\n",
            "Squeeze Tensor => tensor([[8.1604e-02, 5.5777e-01, 5.6519e-01, 3.7949e-01, 3.2019e-01, 1.2512e-02,\n",
            "         1.7232e-01, 6.1989e-01, 2.6611e-01, 8.8171e-01, 4.3468e-01, 4.8534e-01,\n",
            "         6.5356e-01, 8.2544e-01, 5.5690e-03, 7.9273e-01, 3.9011e-01, 9.1248e-01,\n",
            "         4.9983e-01, 1.5944e-01, 9.3060e-01, 3.9573e-01, 9.1588e-01, 5.9542e-01,\n",
            "         1.6326e-01, 6.8410e-01, 4.8002e-01, 8.4797e-01, 4.1669e-01, 8.5191e-01,\n",
            "         1.2811e-01, 5.9065e-02, 5.2418e-01, 4.9123e-01, 3.2916e-01, 7.8653e-01,\n",
            "         8.3126e-01, 1.2715e-01, 8.7355e-01, 7.7170e-01, 4.6341e-01, 9.4083e-01,\n",
            "         7.8896e-01, 7.4822e-01, 6.8038e-01, 7.7032e-01, 6.7850e-01, 3.8958e-01,\n",
            "         9.7527e-01, 3.4469e-01, 8.1498e-01, 8.6578e-01, 6.6221e-01, 8.6281e-01,\n",
            "         4.5094e-01, 7.3580e-01, 6.7423e-01, 3.5662e-01, 5.3104e-02, 9.5417e-01,\n",
            "         9.4645e-01, 1.1101e-01, 6.3186e-01, 2.1569e-01, 6.7742e-01, 6.4431e-01,\n",
            "         2.2300e-01, 9.5500e-01, 1.4852e-02, 8.3962e-01, 6.9381e-01, 3.3548e-01,\n",
            "         4.9906e-01, 3.4343e-01, 5.6934e-01, 8.1845e-01, 2.6498e-01, 6.8615e-01,\n",
            "         4.3283e-02, 1.7469e-01, 1.8154e-01, 1.4030e-01, 6.9019e-01, 9.9014e-01,\n",
            "         1.6014e-01, 2.7892e-01, 5.7342e-01, 8.6232e-01, 9.1273e-01, 3.6259e-01,\n",
            "         2.1953e-01, 8.8377e-01, 4.7724e-01, 2.9237e-01, 3.9218e-01, 7.8276e-01,\n",
            "         1.0560e-01, 8.2764e-01, 1.3670e-01, 7.3285e-01],\n",
            "        [4.9379e-01, 4.7179e-01, 5.4416e-02, 4.4436e-01, 3.2117e-01, 3.7833e-01,\n",
            "         6.2396e-01, 5.8305e-01, 8.8853e-01, 7.1775e-01, 8.8945e-01, 3.8520e-01,\n",
            "         8.8743e-01, 2.5975e-01, 1.0780e-01, 3.5379e-01, 7.2312e-01, 5.7147e-01,\n",
            "         4.7541e-01, 3.3298e-01, 2.6006e-01, 6.9873e-01, 3.7825e-01, 9.2003e-01,\n",
            "         1.1777e-01, 1.3912e-01, 7.4862e-01, 1.3541e-01, 2.5663e-01, 8.3319e-02,\n",
            "         3.4187e-03, 1.1694e-01, 1.4547e-01, 6.4514e-01, 9.1890e-01, 7.3544e-02,\n",
            "         4.7098e-01, 4.3243e-01, 8.0100e-01, 5.1714e-01, 8.3063e-01, 7.8397e-01,\n",
            "         5.9988e-01, 1.1653e-01, 8.3550e-01, 6.5963e-01, 9.9422e-01, 7.2435e-01,\n",
            "         8.6224e-01, 5.7468e-01, 6.5998e-01, 4.4009e-01, 3.2861e-01, 8.8829e-01,\n",
            "         8.0788e-01, 2.9573e-01, 6.9762e-01, 9.5532e-01, 1.3452e-01, 4.4884e-01,\n",
            "         9.7599e-01, 8.9558e-01, 1.8005e-01, 7.0973e-01, 7.8130e-01, 1.6482e-01,\n",
            "         9.3218e-01, 2.6945e-02, 5.5373e-01, 9.1742e-01, 3.4987e-01, 1.6252e-01,\n",
            "         9.9281e-01, 6.5369e-01, 5.9247e-01, 6.4272e-03, 6.2088e-01, 3.2128e-01,\n",
            "         9.7426e-01, 8.2028e-01, 8.9175e-01, 6.2385e-01, 4.3105e-01, 2.3491e-01,\n",
            "         4.2317e-02, 8.4752e-01, 1.5455e-01, 2.7437e-01, 8.2425e-01, 2.5594e-01,\n",
            "         2.0665e-01, 1.8698e-01, 9.8314e-01, 7.8676e-01, 1.4423e-01, 1.6599e-01,\n",
            "         6.6638e-01, 4.6804e-01, 4.2403e-01, 1.5219e-02],\n",
            "        [8.9710e-01, 3.8614e-01, 9.1983e-01, 3.2239e-01, 7.5455e-01, 2.0981e-01,\n",
            "         1.1402e-01, 9.0821e-01, 4.9300e-01, 9.6049e-01, 2.4092e-01, 5.3498e-01,\n",
            "         8.3712e-01, 7.9205e-01, 4.0875e-01, 1.6997e-01, 2.7440e-01, 4.6876e-01,\n",
            "         4.8785e-01, 3.9914e-01, 2.9420e-01, 1.5941e-01, 6.3762e-01, 1.9890e-01,\n",
            "         3.7626e-01, 2.0711e-02, 6.4073e-01, 3.8797e-01, 4.4856e-01, 3.0641e-01,\n",
            "         5.1959e-01, 2.9773e-01, 5.6938e-01, 7.2921e-01, 5.9699e-01, 8.5356e-01,\n",
            "         1.6477e-01, 6.9372e-01, 7.2739e-01, 7.8713e-01, 2.8702e-01, 2.5858e-01,\n",
            "         7.5933e-01, 8.2470e-01, 4.8321e-02, 5.8675e-01, 4.8427e-01, 5.4681e-01,\n",
            "         6.0229e-01, 4.8146e-01, 9.8026e-01, 2.1456e-01, 3.1532e-02, 1.1794e-01,\n",
            "         3.8199e-01, 1.5283e-01, 8.8701e-01, 5.7179e-01, 9.4359e-01, 3.8320e-01,\n",
            "         9.6146e-01, 8.2092e-01, 8.8474e-01, 7.2843e-01, 5.3729e-01, 1.7147e-01,\n",
            "         8.1177e-01, 3.4561e-02, 8.7886e-01, 2.3712e-02, 1.4595e-02, 2.4431e-01,\n",
            "         9.5750e-01, 7.5839e-01, 7.3774e-01, 7.1405e-01, 9.2229e-01, 7.5880e-01,\n",
            "         8.7377e-01, 7.5622e-01, 3.9538e-01, 2.4556e-01, 8.4242e-01, 5.3809e-01,\n",
            "         5.6869e-01, 9.2777e-01, 2.3969e-01, 5.5497e-01, 6.0058e-01, 7.3298e-01,\n",
            "         7.3540e-01, 1.2897e-01, 3.8541e-01, 6.0954e-01, 4.7350e-01, 7.9805e-01,\n",
            "         3.1176e-01, 7.6926e-01, 3.0273e-01, 8.3686e-01],\n",
            "        [8.5666e-01, 4.1014e-01, 7.5651e-02, 2.2745e-01, 6.0618e-01, 3.6895e-01,\n",
            "         8.8093e-01, 7.9922e-01, 5.7872e-01, 5.1862e-01, 3.9345e-01, 5.8056e-01,\n",
            "         4.7532e-01, 4.0924e-01, 1.2129e-01, 2.8682e-01, 5.8737e-01, 2.9768e-01,\n",
            "         9.0810e-01, 4.9628e-01, 1.3460e-01, 7.5155e-04, 2.2354e-01, 6.6266e-01,\n",
            "         5.1926e-02, 7.5302e-01, 4.6018e-01, 2.3694e-01, 1.7598e-01, 9.5301e-01,\n",
            "         2.4007e-01, 7.6604e-01, 6.4258e-01, 8.4256e-02, 4.3477e-01, 7.1603e-02,\n",
            "         3.8188e-01, 8.9135e-01, 2.0361e-01, 6.6801e-01, 8.4255e-01, 8.2312e-01,\n",
            "         2.7793e-01, 1.4844e-02, 1.9442e-01, 5.2749e-01, 1.8118e-01, 4.3881e-01,\n",
            "         6.5011e-01, 7.2415e-01, 7.9951e-01, 7.2039e-01, 3.3775e-01, 2.6525e-01,\n",
            "         9.9489e-01, 5.0473e-02, 2.6831e-02, 9.5467e-01, 5.0583e-03, 5.2839e-01,\n",
            "         6.5688e-01, 4.0454e-02, 4.9444e-01, 1.2266e-01, 8.5652e-01, 7.6906e-01,\n",
            "         9.6811e-01, 4.3548e-01, 8.9473e-01, 5.5119e-01, 8.1008e-01, 5.3387e-01,\n",
            "         7.4509e-01, 4.3774e-01, 4.2295e-02, 6.3805e-01, 9.3541e-01, 6.1343e-01,\n",
            "         7.4858e-01, 6.1320e-01, 6.5144e-01, 8.8216e-01, 6.6199e-01, 8.2705e-01,\n",
            "         6.3482e-02, 4.3303e-01, 8.2646e-01, 2.9834e-01, 3.5401e-01, 5.2112e-01,\n",
            "         8.0164e-01, 4.5772e-01, 1.9599e-01, 8.0110e-01, 9.7125e-01, 4.0026e-01,\n",
            "         9.9644e-01, 1.5238e-02, 2.1858e-01, 3.3094e-01],\n",
            "        [5.5760e-01, 2.4287e-02, 2.3710e-01, 8.1990e-01, 5.3880e-01, 5.6573e-02,\n",
            "         3.5348e-01, 9.8622e-01, 3.6928e-01, 8.8121e-01, 9.0502e-01, 4.4158e-01,\n",
            "         6.7281e-01, 8.3276e-01, 6.6396e-01, 3.9647e-01, 6.5557e-01, 8.3160e-02,\n",
            "         8.3060e-01, 5.8533e-01, 1.9888e-01, 6.0536e-01, 7.4321e-01, 7.8743e-01,\n",
            "         5.1744e-01, 9.3815e-01, 5.9315e-01, 7.3235e-01, 9.8011e-01, 2.9319e-01,\n",
            "         7.7446e-01, 4.0531e-01, 7.4763e-01, 1.8435e-01, 1.6122e-01, 5.1568e-02,\n",
            "         1.7039e-01, 4.7281e-01, 6.9080e-01, 5.2760e-01, 8.8943e-01, 6.3504e-01,\n",
            "         8.1975e-01, 1.8367e-01, 3.4998e-01, 7.4728e-01, 9.5700e-01, 2.7789e-01,\n",
            "         1.7008e-01, 2.7849e-01, 6.3448e-01, 8.2628e-01, 7.5297e-01, 6.8430e-01,\n",
            "         5.4233e-01, 8.9443e-02, 8.2021e-02, 6.6746e-02, 4.6808e-01, 6.8834e-01,\n",
            "         9.7994e-01, 5.5460e-01, 6.2737e-01, 5.1655e-01, 5.5226e-01, 8.1527e-01,\n",
            "         3.7730e-01, 3.8661e-01, 7.5906e-01, 7.3761e-01, 1.9154e-01, 2.4236e-01,\n",
            "         3.1135e-01, 8.2483e-01, 2.3637e-01, 6.1773e-01, 7.3636e-01, 1.1177e-01,\n",
            "         7.0790e-02, 8.9771e-01, 3.6944e-01, 2.8843e-01, 2.1256e-01, 1.2428e-01,\n",
            "         2.6285e-01, 8.5046e-01, 1.4815e-01, 3.5555e-02, 6.6550e-01, 1.4833e-02,\n",
            "         4.6746e-01, 6.4069e-01, 8.6999e-02, 6.5289e-02, 5.8209e-01, 5.6635e-01,\n",
            "         4.5597e-01, 3.4372e-01, 8.0028e-01, 9.9415e-01],\n",
            "        [4.9216e-01, 2.2926e-01, 9.0298e-01, 5.2460e-01, 5.8827e-01, 2.1132e-01,\n",
            "         6.1273e-01, 5.9781e-01, 9.4003e-01, 2.3373e-01, 9.1015e-01, 8.6877e-01,\n",
            "         7.6851e-01, 7.7474e-02, 2.4443e-01, 1.3557e-01, 9.6276e-01, 3.9708e-01,\n",
            "         1.7116e-01, 2.5752e-01, 6.1215e-01, 4.3173e-01, 6.0824e-01, 9.3718e-01,\n",
            "         5.8026e-01, 7.0295e-01, 8.2294e-02, 3.2328e-01, 3.8144e-01, 7.0627e-01,\n",
            "         4.7214e-01, 9.1737e-01, 1.1425e-01, 6.8436e-01, 1.5304e-01, 7.7538e-01,\n",
            "         1.4189e-01, 3.9480e-01, 6.6934e-01, 3.8167e-01, 5.7738e-01, 8.8676e-01,\n",
            "         5.0065e-01, 4.3308e-01, 6.5484e-02, 2.7814e-01, 3.6086e-01, 5.1347e-01,\n",
            "         9.3324e-01, 5.9976e-01, 7.4165e-02, 8.0759e-01, 3.9357e-01, 6.6381e-01,\n",
            "         4.0661e-01, 7.3815e-02, 5.9148e-02, 7.9355e-01, 1.7464e-01, 7.3468e-01,\n",
            "         2.4547e-01, 1.6831e-01, 8.1506e-01, 1.1917e-01, 7.5982e-01, 2.2406e-01,\n",
            "         8.3595e-02, 3.6903e-01, 2.2881e-02, 6.9469e-01, 5.6277e-02, 2.4852e-01,\n",
            "         2.6646e-01, 8.9334e-01, 8.5232e-01, 1.0116e-01, 9.7033e-01, 8.1707e-01,\n",
            "         2.7544e-01, 9.9243e-01, 1.3152e-01, 5.3615e-01, 1.8501e-01, 3.4566e-01,\n",
            "         6.7314e-02, 5.3763e-01, 8.7770e-01, 1.2453e-02, 3.3808e-01, 3.1706e-01,\n",
            "         1.0941e-01, 7.8152e-01, 4.5194e-01, 8.5031e-01, 8.2695e-01, 9.3166e-01,\n",
            "         2.2278e-01, 8.9762e-01, 5.4592e-01, 9.7383e-02],\n",
            "        [4.9688e-01, 6.0564e-01, 1.0975e-01, 4.6906e-01, 7.5482e-01, 1.3295e-01,\n",
            "         1.4914e-02, 9.2749e-01, 8.4527e-01, 7.3350e-01, 6.3306e-01, 9.4032e-01,\n",
            "         2.8511e-01, 7.5571e-01, 3.7585e-01, 2.0939e-01, 6.3213e-01, 4.2246e-01,\n",
            "         1.2931e-01, 5.3284e-01, 7.6758e-01, 6.7461e-01, 6.2525e-01, 4.7481e-01,\n",
            "         7.9622e-01, 4.8895e-01, 8.6369e-01, 2.5319e-01, 7.2130e-02, 8.5200e-01,\n",
            "         9.6786e-01, 3.9654e-01, 4.2059e-01, 9.2551e-01, 4.9140e-01, 5.9309e-01,\n",
            "         3.9196e-01, 8.5716e-01, 7.7089e-02, 4.7541e-01, 3.1886e-02, 8.1179e-01,\n",
            "         3.8046e-01, 9.3863e-01, 3.1259e-02, 9.5448e-01, 8.3809e-01, 8.4015e-01,\n",
            "         5.5805e-01, 1.8507e-02, 5.3514e-01, 7.4110e-01, 1.9651e-01, 3.7031e-03,\n",
            "         8.9149e-01, 4.1730e-02, 1.9716e-01, 5.2132e-01, 3.5379e-01, 7.5895e-01,\n",
            "         2.6121e-01, 2.3325e-01, 7.7538e-01, 8.2272e-01, 5.3274e-01, 3.4224e-01,\n",
            "         7.5411e-01, 6.0686e-01, 8.2289e-01, 2.1956e-01, 9.6206e-01, 2.1804e-01,\n",
            "         5.9248e-01, 1.9277e-01, 4.3712e-01, 2.7056e-02, 7.4482e-02, 9.2578e-01,\n",
            "         3.5622e-02, 9.3093e-01, 7.4074e-01, 6.0816e-02, 3.1421e-01, 3.5951e-01,\n",
            "         1.8807e-02, 3.1099e-01, 6.1311e-01, 5.5567e-02, 2.5482e-01, 5.0629e-01,\n",
            "         6.0218e-01, 2.1629e-01, 6.6213e-01, 9.6920e-01, 3.0341e-02, 5.9581e-01,\n",
            "         4.6293e-02, 1.8732e-01, 1.0272e-01, 5.0797e-01],\n",
            "        [9.1922e-02, 2.2984e-01, 9.2291e-01, 1.6880e-01, 3.4835e-01, 8.3818e-01,\n",
            "         4.8758e-01, 5.7774e-01, 9.0886e-01, 8.6973e-01, 4.6522e-02, 8.2608e-01,\n",
            "         7.5623e-01, 7.1496e-01, 5.3306e-01, 2.1942e-01, 8.9613e-01, 2.9938e-01,\n",
            "         4.6249e-01, 9.8408e-01, 3.8674e-01, 5.1225e-01, 9.7515e-01, 3.0752e-01,\n",
            "         8.0774e-01, 9.9406e-01, 1.9198e-02, 6.3799e-01, 1.3960e-01, 8.0611e-01,\n",
            "         7.1206e-01, 9.1977e-01, 3.1428e-01, 4.0985e-01, 7.9711e-02, 7.3937e-01,\n",
            "         6.7437e-01, 5.0170e-01, 5.2236e-01, 4.6456e-01, 1.3023e-01, 1.6083e-01,\n",
            "         3.8296e-01, 9.8477e-01, 9.6826e-01, 1.6527e-01, 8.7771e-02, 4.9545e-01,\n",
            "         2.4207e-01, 3.7992e-01, 7.1440e-01, 6.7005e-01, 4.9089e-01, 6.1760e-01,\n",
            "         8.2575e-01, 1.9467e-01, 7.6233e-01, 3.6020e-01, 7.0424e-01, 9.5864e-01,\n",
            "         6.8257e-01, 1.4502e-01, 4.0414e-01, 5.1002e-01, 8.3246e-01, 8.4279e-02,\n",
            "         7.3733e-01, 8.4785e-01, 5.4074e-01, 5.7334e-01, 6.9740e-01, 5.8486e-01,\n",
            "         4.2189e-01, 6.0167e-02, 6.1128e-01, 1.1322e-03, 2.1129e-01, 4.2087e-01,\n",
            "         7.7676e-01, 4.7528e-01, 3.4107e-01, 5.6177e-01, 7.0480e-02, 3.8296e-01,\n",
            "         7.1026e-01, 5.2474e-01, 3.2610e-01, 2.4301e-01, 5.6124e-01, 1.4933e-01,\n",
            "         2.4445e-01, 3.9273e-01, 4.7381e-02, 4.9978e-01, 3.7503e-01, 2.6423e-01,\n",
            "         7.4381e-01, 2.1931e-01, 3.1156e-01, 2.6164e-01],\n",
            "        [7.8031e-01, 9.2238e-01, 5.9437e-01, 2.2310e-01, 9.1493e-01, 4.7888e-02,\n",
            "         1.9700e-01, 4.5609e-01, 4.7607e-01, 8.0723e-01, 3.6083e-01, 9.9307e-02,\n",
            "         1.4651e-01, 5.2565e-01, 2.8749e-01, 3.8038e-01, 8.3197e-01, 4.6182e-01,\n",
            "         7.7102e-01, 8.1967e-01, 9.2963e-02, 5.6504e-01, 6.7127e-01, 6.2465e-01,\n",
            "         9.1402e-02, 8.6855e-01, 8.3324e-01, 9.6535e-01, 9.9604e-01, 9.8357e-02,\n",
            "         4.3758e-01, 6.9799e-01, 6.2288e-01, 2.0490e-01, 6.3233e-01, 5.1610e-01,\n",
            "         2.4545e-01, 3.2241e-01, 4.2124e-01, 2.4819e-01, 9.6619e-01, 9.9727e-01,\n",
            "         2.2853e-01, 8.0506e-02, 8.2617e-01, 8.8029e-01, 9.0084e-01, 8.8318e-01,\n",
            "         4.9683e-01, 1.2244e-01, 7.8584e-01, 6.3234e-01, 2.6526e-01, 6.1956e-01,\n",
            "         8.9735e-01, 5.9981e-01, 9.1454e-01, 3.9219e-01, 8.1973e-02, 3.8248e-01,\n",
            "         2.2588e-03, 8.3259e-02, 9.1844e-01, 9.9542e-01, 8.8968e-02, 9.2397e-02,\n",
            "         9.2259e-01, 9.6676e-01, 3.1658e-01, 4.6494e-01, 9.5755e-01, 5.5791e-01,\n",
            "         5.5294e-01, 2.5004e-01, 2.7448e-01, 7.7983e-01, 6.6146e-01, 2.0756e-01,\n",
            "         7.3926e-01, 4.6697e-01, 4.7706e-02, 2.8990e-01, 8.0746e-01, 3.6450e-01,\n",
            "         9.4200e-01, 4.8792e-01, 4.3089e-01, 8.9807e-01, 5.8669e-01, 8.2714e-01,\n",
            "         2.5559e-02, 5.9312e-01, 2.3710e-01, 9.0918e-01, 5.3074e-01, 8.8331e-01,\n",
            "         2.6732e-01, 4.6857e-01, 2.4054e-01, 4.1548e-02],\n",
            "        [5.0777e-01, 7.3561e-01, 3.0758e-01, 9.0041e-01, 8.7596e-01, 2.8808e-01,\n",
            "         5.6304e-01, 6.6406e-01, 7.1591e-01, 6.6498e-01, 5.7052e-02, 3.5576e-01,\n",
            "         1.2584e-01, 7.0323e-01, 9.3095e-01, 9.2346e-01, 8.3435e-01, 6.6363e-01,\n",
            "         4.9003e-01, 9.3112e-01, 2.9740e-01, 7.4738e-01, 8.8002e-01, 6.7925e-01,\n",
            "         1.0912e-01, 2.2722e-01, 1.6617e-01, 4.9386e-01, 8.9069e-01, 8.0928e-01,\n",
            "         5.5567e-02, 5.2950e-01, 8.4768e-01, 3.2670e-01, 2.6487e-01, 6.9438e-01,\n",
            "         2.4298e-01, 2.0627e-01, 4.2871e-01, 9.1508e-01, 8.4105e-01, 4.8293e-01,\n",
            "         1.5354e-01, 9.0041e-01, 9.4235e-01, 2.0541e-01, 6.4841e-01, 4.4715e-01,\n",
            "         8.5982e-01, 9.8417e-01, 7.8113e-01, 6.4699e-01, 8.1906e-01, 1.2873e-01,\n",
            "         8.2257e-01, 8.9249e-01, 9.7299e-01, 7.3562e-01, 8.9181e-01, 7.6237e-02,\n",
            "         1.3581e-01, 5.2349e-01, 1.3105e-01, 9.4061e-01, 5.3122e-02, 2.2651e-01,\n",
            "         8.8751e-02, 6.8909e-01, 3.4628e-01, 9.5912e-01, 6.7650e-01, 7.2814e-01,\n",
            "         7.2114e-01, 3.6751e-01, 1.0379e-01, 5.3341e-01, 3.5823e-01, 6.2625e-01,\n",
            "         2.0114e-01, 2.0115e-01, 4.4724e-01, 4.6196e-01, 8.3058e-02, 6.1603e-01,\n",
            "         7.7117e-01, 7.5126e-01, 6.8695e-01, 4.4773e-01, 5.4067e-01, 2.0093e-01,\n",
            "         1.1027e-01, 5.9807e-01, 6.0012e-01, 8.3143e-01, 5.5640e-01, 8.2894e-01,\n",
            "         7.0163e-01, 3.9171e-01, 1.4883e-01, 7.4562e-01]])\n",
            "Shape of Squeeze Tensor => torch.Size([10, 100])\n"
          ]
        }
      ],
      "source": [
        "___ = torch.rand(1, 10, 100)\n",
        "__ = torch.squeeze(___, 0)\n",
        "print(f\"Sample Tensor => {___}\")\n",
        "print(f\"Shape of sample Tensor => {___.shape}\")\n",
        "print(f\"Squeeze Tensor => {__}\")\n",
        "print(f\"Shape of Squeeze Tensor => {__.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhhYnvHcDWTl",
        "outputId": "fb984864-08a6-488e-a714-affec29acb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[8.1604e-02, 5.5777e-01, 5.6519e-01, 3.7949e-01, 3.2019e-01,\n",
            "          1.2512e-02, 1.7232e-01, 6.1989e-01, 2.6611e-01, 8.8171e-01,\n",
            "          4.3468e-01, 4.8534e-01, 6.5356e-01, 8.2544e-01, 5.5690e-03,\n",
            "          7.9273e-01, 3.9011e-01, 9.1248e-01, 4.9983e-01, 1.5944e-01,\n",
            "          9.3060e-01, 3.9573e-01, 9.1588e-01, 5.9542e-01, 1.6326e-01,\n",
            "          6.8410e-01, 4.8002e-01, 8.4797e-01, 4.1669e-01, 8.5191e-01,\n",
            "          1.2811e-01, 5.9065e-02, 5.2418e-01, 4.9123e-01, 3.2916e-01,\n",
            "          7.8653e-01, 8.3126e-01, 1.2715e-01, 8.7355e-01, 7.7170e-01,\n",
            "          4.6341e-01, 9.4083e-01, 7.8896e-01, 7.4822e-01, 6.8038e-01,\n",
            "          7.7032e-01, 6.7850e-01, 3.8958e-01, 9.7527e-01, 3.4469e-01,\n",
            "          8.1498e-01, 8.6578e-01, 6.6221e-01, 8.6281e-01, 4.5094e-01,\n",
            "          7.3580e-01, 6.7423e-01, 3.5662e-01, 5.3104e-02, 9.5417e-01,\n",
            "          9.4645e-01, 1.1101e-01, 6.3186e-01, 2.1569e-01, 6.7742e-01,\n",
            "          6.4431e-01, 2.2300e-01, 9.5500e-01, 1.4852e-02, 8.3962e-01,\n",
            "          6.9381e-01, 3.3548e-01, 4.9906e-01, 3.4343e-01, 5.6934e-01,\n",
            "          8.1845e-01, 2.6498e-01, 6.8615e-01, 4.3283e-02, 1.7469e-01,\n",
            "          1.8154e-01, 1.4030e-01, 6.9019e-01, 9.9014e-01, 1.6014e-01,\n",
            "          2.7892e-01, 5.7342e-01, 8.6232e-01, 9.1273e-01, 3.6259e-01,\n",
            "          2.1953e-01, 8.8377e-01, 4.7724e-01, 2.9237e-01, 3.9218e-01,\n",
            "          7.8276e-01, 1.0560e-01, 8.2764e-01, 1.3670e-01, 7.3285e-01],\n",
            "         [4.9379e-01, 4.7179e-01, 5.4416e-02, 4.4436e-01, 3.2117e-01,\n",
            "          3.7833e-01, 6.2396e-01, 5.8305e-01, 8.8853e-01, 7.1775e-01,\n",
            "          8.8945e-01, 3.8520e-01, 8.8743e-01, 2.5975e-01, 1.0780e-01,\n",
            "          3.5379e-01, 7.2312e-01, 5.7147e-01, 4.7541e-01, 3.3298e-01,\n",
            "          2.6006e-01, 6.9873e-01, 3.7825e-01, 9.2003e-01, 1.1777e-01,\n",
            "          1.3912e-01, 7.4862e-01, 1.3541e-01, 2.5663e-01, 8.3319e-02,\n",
            "          3.4187e-03, 1.1694e-01, 1.4547e-01, 6.4514e-01, 9.1890e-01,\n",
            "          7.3544e-02, 4.7098e-01, 4.3243e-01, 8.0100e-01, 5.1714e-01,\n",
            "          8.3063e-01, 7.8397e-01, 5.9988e-01, 1.1653e-01, 8.3550e-01,\n",
            "          6.5963e-01, 9.9422e-01, 7.2435e-01, 8.6224e-01, 5.7468e-01,\n",
            "          6.5998e-01, 4.4009e-01, 3.2861e-01, 8.8829e-01, 8.0788e-01,\n",
            "          2.9573e-01, 6.9762e-01, 9.5532e-01, 1.3452e-01, 4.4884e-01,\n",
            "          9.7599e-01, 8.9558e-01, 1.8005e-01, 7.0973e-01, 7.8130e-01,\n",
            "          1.6482e-01, 9.3218e-01, 2.6945e-02, 5.5373e-01, 9.1742e-01,\n",
            "          3.4987e-01, 1.6252e-01, 9.9281e-01, 6.5369e-01, 5.9247e-01,\n",
            "          6.4272e-03, 6.2088e-01, 3.2128e-01, 9.7426e-01, 8.2028e-01,\n",
            "          8.9175e-01, 6.2385e-01, 4.3105e-01, 2.3491e-01, 4.2317e-02,\n",
            "          8.4752e-01, 1.5455e-01, 2.7437e-01, 8.2425e-01, 2.5594e-01,\n",
            "          2.0665e-01, 1.8698e-01, 9.8314e-01, 7.8676e-01, 1.4423e-01,\n",
            "          1.6599e-01, 6.6638e-01, 4.6804e-01, 4.2403e-01, 1.5219e-02],\n",
            "         [8.9710e-01, 3.8614e-01, 9.1983e-01, 3.2239e-01, 7.5455e-01,\n",
            "          2.0981e-01, 1.1402e-01, 9.0821e-01, 4.9300e-01, 9.6049e-01,\n",
            "          2.4092e-01, 5.3498e-01, 8.3712e-01, 7.9205e-01, 4.0875e-01,\n",
            "          1.6997e-01, 2.7440e-01, 4.6876e-01, 4.8785e-01, 3.9914e-01,\n",
            "          2.9420e-01, 1.5941e-01, 6.3762e-01, 1.9890e-01, 3.7626e-01,\n",
            "          2.0711e-02, 6.4073e-01, 3.8797e-01, 4.4856e-01, 3.0641e-01,\n",
            "          5.1959e-01, 2.9773e-01, 5.6938e-01, 7.2921e-01, 5.9699e-01,\n",
            "          8.5356e-01, 1.6477e-01, 6.9372e-01, 7.2739e-01, 7.8713e-01,\n",
            "          2.8702e-01, 2.5858e-01, 7.5933e-01, 8.2470e-01, 4.8321e-02,\n",
            "          5.8675e-01, 4.8427e-01, 5.4681e-01, 6.0229e-01, 4.8146e-01,\n",
            "          9.8026e-01, 2.1456e-01, 3.1532e-02, 1.1794e-01, 3.8199e-01,\n",
            "          1.5283e-01, 8.8701e-01, 5.7179e-01, 9.4359e-01, 3.8320e-01,\n",
            "          9.6146e-01, 8.2092e-01, 8.8474e-01, 7.2843e-01, 5.3729e-01,\n",
            "          1.7147e-01, 8.1177e-01, 3.4561e-02, 8.7886e-01, 2.3712e-02,\n",
            "          1.4595e-02, 2.4431e-01, 9.5750e-01, 7.5839e-01, 7.3774e-01,\n",
            "          7.1405e-01, 9.2229e-01, 7.5880e-01, 8.7377e-01, 7.5622e-01,\n",
            "          3.9538e-01, 2.4556e-01, 8.4242e-01, 5.3809e-01, 5.6869e-01,\n",
            "          9.2777e-01, 2.3969e-01, 5.5497e-01, 6.0058e-01, 7.3298e-01,\n",
            "          7.3540e-01, 1.2897e-01, 3.8541e-01, 6.0954e-01, 4.7350e-01,\n",
            "          7.9805e-01, 3.1176e-01, 7.6926e-01, 3.0273e-01, 8.3686e-01],\n",
            "         [8.5666e-01, 4.1014e-01, 7.5651e-02, 2.2745e-01, 6.0618e-01,\n",
            "          3.6895e-01, 8.8093e-01, 7.9922e-01, 5.7872e-01, 5.1862e-01,\n",
            "          3.9345e-01, 5.8056e-01, 4.7532e-01, 4.0924e-01, 1.2129e-01,\n",
            "          2.8682e-01, 5.8737e-01, 2.9768e-01, 9.0810e-01, 4.9628e-01,\n",
            "          1.3460e-01, 7.5155e-04, 2.2354e-01, 6.6266e-01, 5.1926e-02,\n",
            "          7.5302e-01, 4.6018e-01, 2.3694e-01, 1.7598e-01, 9.5301e-01,\n",
            "          2.4007e-01, 7.6604e-01, 6.4258e-01, 8.4256e-02, 4.3477e-01,\n",
            "          7.1603e-02, 3.8188e-01, 8.9135e-01, 2.0361e-01, 6.6801e-01,\n",
            "          8.4255e-01, 8.2312e-01, 2.7793e-01, 1.4844e-02, 1.9442e-01,\n",
            "          5.2749e-01, 1.8118e-01, 4.3881e-01, 6.5011e-01, 7.2415e-01,\n",
            "          7.9951e-01, 7.2039e-01, 3.3775e-01, 2.6525e-01, 9.9489e-01,\n",
            "          5.0473e-02, 2.6831e-02, 9.5467e-01, 5.0583e-03, 5.2839e-01,\n",
            "          6.5688e-01, 4.0454e-02, 4.9444e-01, 1.2266e-01, 8.5652e-01,\n",
            "          7.6906e-01, 9.6811e-01, 4.3548e-01, 8.9473e-01, 5.5119e-01,\n",
            "          8.1008e-01, 5.3387e-01, 7.4509e-01, 4.3774e-01, 4.2295e-02,\n",
            "          6.3805e-01, 9.3541e-01, 6.1343e-01, 7.4858e-01, 6.1320e-01,\n",
            "          6.5144e-01, 8.8216e-01, 6.6199e-01, 8.2705e-01, 6.3482e-02,\n",
            "          4.3303e-01, 8.2646e-01, 2.9834e-01, 3.5401e-01, 5.2112e-01,\n",
            "          8.0164e-01, 4.5772e-01, 1.9599e-01, 8.0110e-01, 9.7125e-01,\n",
            "          4.0026e-01, 9.9644e-01, 1.5238e-02, 2.1858e-01, 3.3094e-01],\n",
            "         [5.5760e-01, 2.4287e-02, 2.3710e-01, 8.1990e-01, 5.3880e-01,\n",
            "          5.6573e-02, 3.5348e-01, 9.8622e-01, 3.6928e-01, 8.8121e-01,\n",
            "          9.0502e-01, 4.4158e-01, 6.7281e-01, 8.3276e-01, 6.6396e-01,\n",
            "          3.9647e-01, 6.5557e-01, 8.3160e-02, 8.3060e-01, 5.8533e-01,\n",
            "          1.9888e-01, 6.0536e-01, 7.4321e-01, 7.8743e-01, 5.1744e-01,\n",
            "          9.3815e-01, 5.9315e-01, 7.3235e-01, 9.8011e-01, 2.9319e-01,\n",
            "          7.7446e-01, 4.0531e-01, 7.4763e-01, 1.8435e-01, 1.6122e-01,\n",
            "          5.1568e-02, 1.7039e-01, 4.7281e-01, 6.9080e-01, 5.2760e-01,\n",
            "          8.8943e-01, 6.3504e-01, 8.1975e-01, 1.8367e-01, 3.4998e-01,\n",
            "          7.4728e-01, 9.5700e-01, 2.7789e-01, 1.7008e-01, 2.7849e-01,\n",
            "          6.3448e-01, 8.2628e-01, 7.5297e-01, 6.8430e-01, 5.4233e-01,\n",
            "          8.9443e-02, 8.2021e-02, 6.6746e-02, 4.6808e-01, 6.8834e-01,\n",
            "          9.7994e-01, 5.5460e-01, 6.2737e-01, 5.1655e-01, 5.5226e-01,\n",
            "          8.1527e-01, 3.7730e-01, 3.8661e-01, 7.5906e-01, 7.3761e-01,\n",
            "          1.9154e-01, 2.4236e-01, 3.1135e-01, 8.2483e-01, 2.3637e-01,\n",
            "          6.1773e-01, 7.3636e-01, 1.1177e-01, 7.0790e-02, 8.9771e-01,\n",
            "          3.6944e-01, 2.8843e-01, 2.1256e-01, 1.2428e-01, 2.6285e-01,\n",
            "          8.5046e-01, 1.4815e-01, 3.5555e-02, 6.6550e-01, 1.4833e-02,\n",
            "          4.6746e-01, 6.4069e-01, 8.6999e-02, 6.5289e-02, 5.8209e-01,\n",
            "          5.6635e-01, 4.5597e-01, 3.4372e-01, 8.0028e-01, 9.9415e-01],\n",
            "         [4.9216e-01, 2.2926e-01, 9.0298e-01, 5.2460e-01, 5.8827e-01,\n",
            "          2.1132e-01, 6.1273e-01, 5.9781e-01, 9.4003e-01, 2.3373e-01,\n",
            "          9.1015e-01, 8.6877e-01, 7.6851e-01, 7.7474e-02, 2.4443e-01,\n",
            "          1.3557e-01, 9.6276e-01, 3.9708e-01, 1.7116e-01, 2.5752e-01,\n",
            "          6.1215e-01, 4.3173e-01, 6.0824e-01, 9.3718e-01, 5.8026e-01,\n",
            "          7.0295e-01, 8.2294e-02, 3.2328e-01, 3.8144e-01, 7.0627e-01,\n",
            "          4.7214e-01, 9.1737e-01, 1.1425e-01, 6.8436e-01, 1.5304e-01,\n",
            "          7.7538e-01, 1.4189e-01, 3.9480e-01, 6.6934e-01, 3.8167e-01,\n",
            "          5.7738e-01, 8.8676e-01, 5.0065e-01, 4.3308e-01, 6.5484e-02,\n",
            "          2.7814e-01, 3.6086e-01, 5.1347e-01, 9.3324e-01, 5.9976e-01,\n",
            "          7.4165e-02, 8.0759e-01, 3.9357e-01, 6.6381e-01, 4.0661e-01,\n",
            "          7.3815e-02, 5.9148e-02, 7.9355e-01, 1.7464e-01, 7.3468e-01,\n",
            "          2.4547e-01, 1.6831e-01, 8.1506e-01, 1.1917e-01, 7.5982e-01,\n",
            "          2.2406e-01, 8.3595e-02, 3.6903e-01, 2.2881e-02, 6.9469e-01,\n",
            "          5.6277e-02, 2.4852e-01, 2.6646e-01, 8.9334e-01, 8.5232e-01,\n",
            "          1.0116e-01, 9.7033e-01, 8.1707e-01, 2.7544e-01, 9.9243e-01,\n",
            "          1.3152e-01, 5.3615e-01, 1.8501e-01, 3.4566e-01, 6.7314e-02,\n",
            "          5.3763e-01, 8.7770e-01, 1.2453e-02, 3.3808e-01, 3.1706e-01,\n",
            "          1.0941e-01, 7.8152e-01, 4.5194e-01, 8.5031e-01, 8.2695e-01,\n",
            "          9.3166e-01, 2.2278e-01, 8.9762e-01, 5.4592e-01, 9.7383e-02],\n",
            "         [4.9688e-01, 6.0564e-01, 1.0975e-01, 4.6906e-01, 7.5482e-01,\n",
            "          1.3295e-01, 1.4914e-02, 9.2749e-01, 8.4527e-01, 7.3350e-01,\n",
            "          6.3306e-01, 9.4032e-01, 2.8511e-01, 7.5571e-01, 3.7585e-01,\n",
            "          2.0939e-01, 6.3213e-01, 4.2246e-01, 1.2931e-01, 5.3284e-01,\n",
            "          7.6758e-01, 6.7461e-01, 6.2525e-01, 4.7481e-01, 7.9622e-01,\n",
            "          4.8895e-01, 8.6369e-01, 2.5319e-01, 7.2130e-02, 8.5200e-01,\n",
            "          9.6786e-01, 3.9654e-01, 4.2059e-01, 9.2551e-01, 4.9140e-01,\n",
            "          5.9309e-01, 3.9196e-01, 8.5716e-01, 7.7089e-02, 4.7541e-01,\n",
            "          3.1886e-02, 8.1179e-01, 3.8046e-01, 9.3863e-01, 3.1259e-02,\n",
            "          9.5448e-01, 8.3809e-01, 8.4015e-01, 5.5805e-01, 1.8507e-02,\n",
            "          5.3514e-01, 7.4110e-01, 1.9651e-01, 3.7031e-03, 8.9149e-01,\n",
            "          4.1730e-02, 1.9716e-01, 5.2132e-01, 3.5379e-01, 7.5895e-01,\n",
            "          2.6121e-01, 2.3325e-01, 7.7538e-01, 8.2272e-01, 5.3274e-01,\n",
            "          3.4224e-01, 7.5411e-01, 6.0686e-01, 8.2289e-01, 2.1956e-01,\n",
            "          9.6206e-01, 2.1804e-01, 5.9248e-01, 1.9277e-01, 4.3712e-01,\n",
            "          2.7056e-02, 7.4482e-02, 9.2578e-01, 3.5622e-02, 9.3093e-01,\n",
            "          7.4074e-01, 6.0816e-02, 3.1421e-01, 3.5951e-01, 1.8807e-02,\n",
            "          3.1099e-01, 6.1311e-01, 5.5567e-02, 2.5482e-01, 5.0629e-01,\n",
            "          6.0218e-01, 2.1629e-01, 6.6213e-01, 9.6920e-01, 3.0341e-02,\n",
            "          5.9581e-01, 4.6293e-02, 1.8732e-01, 1.0272e-01, 5.0797e-01],\n",
            "         [9.1922e-02, 2.2984e-01, 9.2291e-01, 1.6880e-01, 3.4835e-01,\n",
            "          8.3818e-01, 4.8758e-01, 5.7774e-01, 9.0886e-01, 8.6973e-01,\n",
            "          4.6522e-02, 8.2608e-01, 7.5623e-01, 7.1496e-01, 5.3306e-01,\n",
            "          2.1942e-01, 8.9613e-01, 2.9938e-01, 4.6249e-01, 9.8408e-01,\n",
            "          3.8674e-01, 5.1225e-01, 9.7515e-01, 3.0752e-01, 8.0774e-01,\n",
            "          9.9406e-01, 1.9198e-02, 6.3799e-01, 1.3960e-01, 8.0611e-01,\n",
            "          7.1206e-01, 9.1977e-01, 3.1428e-01, 4.0985e-01, 7.9711e-02,\n",
            "          7.3937e-01, 6.7437e-01, 5.0170e-01, 5.2236e-01, 4.6456e-01,\n",
            "          1.3023e-01, 1.6083e-01, 3.8296e-01, 9.8477e-01, 9.6826e-01,\n",
            "          1.6527e-01, 8.7771e-02, 4.9545e-01, 2.4207e-01, 3.7992e-01,\n",
            "          7.1440e-01, 6.7005e-01, 4.9089e-01, 6.1760e-01, 8.2575e-01,\n",
            "          1.9467e-01, 7.6233e-01, 3.6020e-01, 7.0424e-01, 9.5864e-01,\n",
            "          6.8257e-01, 1.4502e-01, 4.0414e-01, 5.1002e-01, 8.3246e-01,\n",
            "          8.4279e-02, 7.3733e-01, 8.4785e-01, 5.4074e-01, 5.7334e-01,\n",
            "          6.9740e-01, 5.8486e-01, 4.2189e-01, 6.0167e-02, 6.1128e-01,\n",
            "          1.1322e-03, 2.1129e-01, 4.2087e-01, 7.7676e-01, 4.7528e-01,\n",
            "          3.4107e-01, 5.6177e-01, 7.0480e-02, 3.8296e-01, 7.1026e-01,\n",
            "          5.2474e-01, 3.2610e-01, 2.4301e-01, 5.6124e-01, 1.4933e-01,\n",
            "          2.4445e-01, 3.9273e-01, 4.7381e-02, 4.9978e-01, 3.7503e-01,\n",
            "          2.6423e-01, 7.4381e-01, 2.1931e-01, 3.1156e-01, 2.6164e-01],\n",
            "         [7.8031e-01, 9.2238e-01, 5.9437e-01, 2.2310e-01, 9.1493e-01,\n",
            "          4.7888e-02, 1.9700e-01, 4.5609e-01, 4.7607e-01, 8.0723e-01,\n",
            "          3.6083e-01, 9.9307e-02, 1.4651e-01, 5.2565e-01, 2.8749e-01,\n",
            "          3.8038e-01, 8.3197e-01, 4.6182e-01, 7.7102e-01, 8.1967e-01,\n",
            "          9.2963e-02, 5.6504e-01, 6.7127e-01, 6.2465e-01, 9.1402e-02,\n",
            "          8.6855e-01, 8.3324e-01, 9.6535e-01, 9.9604e-01, 9.8357e-02,\n",
            "          4.3758e-01, 6.9799e-01, 6.2288e-01, 2.0490e-01, 6.3233e-01,\n",
            "          5.1610e-01, 2.4545e-01, 3.2241e-01, 4.2124e-01, 2.4819e-01,\n",
            "          9.6619e-01, 9.9727e-01, 2.2853e-01, 8.0506e-02, 8.2617e-01,\n",
            "          8.8029e-01, 9.0084e-01, 8.8318e-01, 4.9683e-01, 1.2244e-01,\n",
            "          7.8584e-01, 6.3234e-01, 2.6526e-01, 6.1956e-01, 8.9735e-01,\n",
            "          5.9981e-01, 9.1454e-01, 3.9219e-01, 8.1973e-02, 3.8248e-01,\n",
            "          2.2588e-03, 8.3259e-02, 9.1844e-01, 9.9542e-01, 8.8968e-02,\n",
            "          9.2397e-02, 9.2259e-01, 9.6676e-01, 3.1658e-01, 4.6494e-01,\n",
            "          9.5755e-01, 5.5791e-01, 5.5294e-01, 2.5004e-01, 2.7448e-01,\n",
            "          7.7983e-01, 6.6146e-01, 2.0756e-01, 7.3926e-01, 4.6697e-01,\n",
            "          4.7706e-02, 2.8990e-01, 8.0746e-01, 3.6450e-01, 9.4200e-01,\n",
            "          4.8792e-01, 4.3089e-01, 8.9807e-01, 5.8669e-01, 8.2714e-01,\n",
            "          2.5559e-02, 5.9312e-01, 2.3710e-01, 9.0918e-01, 5.3074e-01,\n",
            "          8.8331e-01, 2.6732e-01, 4.6857e-01, 2.4054e-01, 4.1548e-02],\n",
            "         [5.0777e-01, 7.3561e-01, 3.0758e-01, 9.0041e-01, 8.7596e-01,\n",
            "          2.8808e-01, 5.6304e-01, 6.6406e-01, 7.1591e-01, 6.6498e-01,\n",
            "          5.7052e-02, 3.5576e-01, 1.2584e-01, 7.0323e-01, 9.3095e-01,\n",
            "          9.2346e-01, 8.3435e-01, 6.6363e-01, 4.9003e-01, 9.3112e-01,\n",
            "          2.9740e-01, 7.4738e-01, 8.8002e-01, 6.7925e-01, 1.0912e-01,\n",
            "          2.2722e-01, 1.6617e-01, 4.9386e-01, 8.9069e-01, 8.0928e-01,\n",
            "          5.5567e-02, 5.2950e-01, 8.4768e-01, 3.2670e-01, 2.6487e-01,\n",
            "          6.9438e-01, 2.4298e-01, 2.0627e-01, 4.2871e-01, 9.1508e-01,\n",
            "          8.4105e-01, 4.8293e-01, 1.5354e-01, 9.0041e-01, 9.4235e-01,\n",
            "          2.0541e-01, 6.4841e-01, 4.4715e-01, 8.5982e-01, 9.8417e-01,\n",
            "          7.8113e-01, 6.4699e-01, 8.1906e-01, 1.2873e-01, 8.2257e-01,\n",
            "          8.9249e-01, 9.7299e-01, 7.3562e-01, 8.9181e-01, 7.6237e-02,\n",
            "          1.3581e-01, 5.2349e-01, 1.3105e-01, 9.4061e-01, 5.3122e-02,\n",
            "          2.2651e-01, 8.8751e-02, 6.8909e-01, 3.4628e-01, 9.5912e-01,\n",
            "          6.7650e-01, 7.2814e-01, 7.2114e-01, 3.6751e-01, 1.0379e-01,\n",
            "          5.3341e-01, 3.5823e-01, 6.2625e-01, 2.0114e-01, 2.0115e-01,\n",
            "          4.4724e-01, 4.6196e-01, 8.3058e-02, 6.1603e-01, 7.7117e-01,\n",
            "          7.5126e-01, 6.8695e-01, 4.4773e-01, 5.4067e-01, 2.0093e-01,\n",
            "          1.1027e-01, 5.9807e-01, 6.0012e-01, 8.3143e-01, 5.5640e-01,\n",
            "          8.2894e-01, 7.0163e-01, 3.9171e-01, 1.4883e-01, 7.4562e-01]]])\n",
            "torch.Size([1, 10, 100])\n"
          ]
        }
      ],
      "source": [
        "_ = __.unsqueeze(dim=0)\n",
        "print(_)\n",
        "print(_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J5jfoUqDxHU",
        "outputId": "54e5762e-20b3-4a92-9e66-3f4166868688"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 10, 100]), torch.Size([100, 1, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "___permuted = ___.permute(2, 0, 1) # Shifts axis = 0 -> 1, 1 -> 2, 2 -> 0\n",
        "## Here 2, 0, 1 are the order of dim of prev tensor\n",
        "___.shape, ___permuted.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ei4VNWOFZi1"
      },
      "source": [
        "## Indexing (Selecting data from tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yppJk1LTGMOe",
        "outputId": "fdb2c58b-9b8a-477c-96f7-4ee07343b28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 1,  2,  3],\n",
              "          [ 4,  5,  6],\n",
              "          [ 7,  8,  9]],\n",
              " \n",
              "         [[10, 11, 12],\n",
              "          [13, 14, 15],\n",
              "          [16, 17, 18]]]),\n",
              " torch.Size([2, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "x = torch.arange(1, 19).reshape(2, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekrj1U2UGbs2",
        "outputId": "6ca4373b-9aa3-44f5-8070-edf4904d8873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[ 1,  2,  3],\n",
            "        [10, 11, 12]])\n",
            "tensor([ 2, 11])\n",
            "tensor([[ 1,  4,  7],\n",
            "        [10, 13, 16]])\n",
            "tensor(9)\n",
            "CPU times: user 4.83 ms, sys: 0 ns, total: 4.83 ms\n",
            "Wall time: 5 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "print(x[0])\n",
        "print(x[:, 0])\n",
        "print(x[:, 0, 1])\n",
        "print(x[:, :, 0])\n",
        "print(x[0, 2, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-me0LtGsHK4K"
      },
      "source": [
        "## Pytorch tensors & Numpy\n",
        "* Data in NumPy, want in Pytorch tensor -> `torch.from_numpy(ndarray)`\n",
        "* Pytorch Tensor -> NumPy -> `torch.Tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40n7HButJbZU",
        "outputId": "d95ac5fa-041e-4e4e-ffa8-9789f5ee4a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "array = np.arange(1.0, 8.0) # Default Dtype is float64\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor, tensor.type(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73kFyZ-ybVCr",
        "outputId": "8d803e43-97a1-4a95-e6f1-150afa749689"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwX3Z6XSbVCr"
      },
      "source": [
        "## Tensor to NumPy Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCKDGsRFbVCr",
        "outputId": "4fb8fc39-7860-4c0e-8321-b2b716afd49d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY086c1nbVCr"
      },
      "source": [
        "## Reproducibility (Trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them of the data -> again -> again...`\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlwNv5R0bVCr",
        "outputId": "53970004-9677-4004-81df-b73bb4c32cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1052, 0.9216, 0.6712, 0.3582],\n",
            "        [0.8717, 0.1191, 0.0299, 0.8420],\n",
            "        [0.2476, 0.7796, 0.4216, 0.0824]])\n",
            "tensor([[0.6704, 0.5558, 0.1818, 0.1108],\n",
            "        [0.0818, 0.6537, 0.8927, 0.2921],\n",
            "        [0.5736, 0.4108, 0.8902, 0.0725]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLeD1kpLbVCr",
        "outputId": "111800bd-e0f6-4938-c003-f89c9bd8e48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Let's make some random but reproducible tensor\n",
        "\n",
        "RANDOM_SEED = 42 # Any Random Int\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED) # You need to call Random_seed mannualy for every torch.rand()\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyXVMth2bVCs"
      },
      "source": [
        "## Running tensors and Pytorch objets on the GPU (and making faster computations)\n",
        "\n",
        "*The below cells were run on Google Colab (GPU Configuration) because my macbook doesn't have any GPU*\n",
        "\n",
        "*The Best practice is to use [Device Agnostic](https://pytorch.org/docs/stable/notes/cuda.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyBBqj1JbVCs",
        "outputId": "5f0ac0c7-0fdb-4e60-c0ed-ade5946180a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Check GPU access with PyTorch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOOj7xZgcBi9",
        "outputId": "87991e56-00bc-4cbf-e117-40a4445ab713"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsTwTh4bcJjt",
        "outputId": "254e2680-2b32-490a-cfd5-223af0a32f75"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor\n",
        "%%time\n",
        "tensor = torch.tensor([1, 2, 3], device=device)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctfXmuQJc2Rq",
        "outputId": "ae74ebf9-4e04-4e33-ed31-94fa4ffd76a6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 224 µs, sys: 15 µs, total: 239 µs\n",
            "Wall time: 245 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.tensor([1, 2, 3], device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzdyX4u5dHV3",
        "outputId": "870fb197-2064-4efc-e402-ba17d54c0767"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 98 µs, sys: 10 µs, total: 108 µs\n",
            "Wall time: 99.2 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving tensors back to CPU"
      ],
      "metadata": {
        "id": "Uiu6rIUYddjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform to Numpy\n",
        "\n",
        "test = tensor.cpu().numpy()\n",
        "\n",
        "test_tensor = torch.from_numpy(test)\n",
        "print(test_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCiM4711diLy",
        "outputId": "78ae8365-9986-4fe2-ef00-a578e90730e3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}